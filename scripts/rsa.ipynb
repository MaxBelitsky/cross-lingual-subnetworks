{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representational similarity analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: This is a WIP, I will add actual encoding comparisons here after we train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach and code is taken from: https://arxiv.org/pdf/1905.06401\n",
    "\n",
    "present RSA as a variant of pattern-information analysis, to be applied for understanding neural activation patterns in human brains, for example syntactic computations (Tyler et al., 2013) or sensory cortical processing (Yamins and DiCarlo, 2016). The core idea is to find connections between data from neu-\n",
    "roimaging, behavioral experiments and computational modeling by correlating representations of stimuli in each of these representation spaces via their pairwise (dis)similarities. RSA has also been used for measuring similarities between neural-network representation spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic RSA measures correlation\n",
    "between similarities in two different representa-\n",
    "tions globally, i.e. how close they are in their total-\n",
    "ity. In contrast, diagnostic models answer a more\n",
    "specific question: to what extent a particular type\n",
    "of information can be extracted from a given rep-\n",
    "resentation. For example, while for a particular\n",
    "neural encoding of sentences it may be possible to\n",
    "predict the length of the sentence with high accu-\n",
    "racy, the RSA between this representation and the\n",
    "strings represented only by their length may be rel-\n",
    "atively small in magnitude, since the neural repre-\n",
    "sentation may be encoding many other aspects of\n",
    "the input in addition to its length\n",
    "\n",
    "\n",
    "The scores according to RSA in some cases show a different picture. This is expected, as RSA answers a substantially different question than the other two approaches: it looks at how the whole representations match in their similarity structure, whereas both the diagnostic model and RSAREGRESS focus on the part of the representation that encodes the target information the strongest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_encodings(\n",
    "    rows_test: int = 20, rows_ref: int = 10, cols: int = 300\n",
    ") -> tuple[dict, dict]:\n",
    "    \"\"\"\n",
    "    rows_test: number of sentences in the test\n",
    "    rows_ref: number of sentences in the reference\n",
    "    cols: size of sentence embedding\n",
    "    \"\"\"\n",
    "    encodings1 = {\n",
    "        \"test\": torch.randn(rows_test, cols),\n",
    "        \"ref\": torch.randn(rows_ref, cols),\n",
    "    }\n",
    "    encodings2 = {\n",
    "        \"test\": torch.randn(rows_test, cols),\n",
    "        \"ref\": torch.randn(rows_ref, cols),\n",
    "    }\n",
    "    return encodings1, encodings2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_184826/4287781648.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x, y = torch.tensor(x), torch.tensor(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rsa': -0.04330206289887428,\n",
       " 'rsa_regress': {'mse': {'mean': 0.0033659918466582895,\n",
       "   'std': 0.0007196518294062319,\n",
       "   'alpha': 10},\n",
       "  'r2': {'mean': -41.69127594072556, 'std': 45.69369499187717, 'alpha': 10},\n",
       "  'pearson_r': {'mean': -0.03999999791383733,\n",
       "   'std': 0.2497999276668854,\n",
       "   'alpha': 0.01}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc1, enc2 = get_dummy_encodings()\n",
    "rsa_report(enc1, enc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from: https://github.com/gchrupala/correlating-neural-and-symbolic-representations-of-language/blob/master/rsa/report.py\n",
    "\n",
    "\n",
    "def run_rsa():\n",
    "    #   try:\n",
    "    #       data_sent = json.load(open(\"data/out/ewt.json\"))\n",
    "    #   except FileNotFoundError:\n",
    "    #       S.ewt_json()\n",
    "    #       data_sent = json.load(open(\"data/out/ewt.json\"))\n",
    "    try:\n",
    "        data = torch.load(\"data/out/ewt_embed.pt\")\n",
    "    except FileNotFoundError:\n",
    "        S.ewt_embed()\n",
    "        data = torch.load(\"data/out/ewt_embed.pt\")\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    result[alpha] = dict(bow=dict(), bert=dict(), bert24=dict(), infersent=dict())\n",
    "\n",
    "    data_enc_bow = dict(test=data[\"bow\"][\"test\"], ref=data[\"bow\"][\"ref\"])\n",
    "    result[alpha][\"bow\"] = RSA_report(data_tk, data_enc_bow)\n",
    "    result[alpha][\"bert\"] = dict(random={}, trained={})\n",
    "    result[alpha][\"bert24\"] = dict(random={}, trained={})\n",
    "    result[alpha][\"infersent\"] = dict(random={}, trained={})\n",
    "\n",
    "    for mode in [\"random\", \"trained\"]:\n",
    "        for step in [\"first\", \"last\"]:\n",
    "            result[alpha][\"bert\"][mode][step] = {}\n",
    "            result[alpha][\"bert24\"][mode][step] = {}\n",
    "            for layer in range(12):\n",
    "                logging.info(\n",
    "                    \"Computing RSA/RSA_regress scores for {} {} {}\".format(\n",
    "                        mode, step, layer\n",
    "                    )\n",
    "                )\n",
    "                data_enc = dict(\n",
    "                    test=data[\"bert\"][\"test\"][mode][layer][step],\n",
    "                    ref=data[\"bert\"][\"ref\"][mode][layer][step],\n",
    "                )\n",
    "                result[alpha][\"bert\"][mode][step][layer] = RSA_report(data_tk, data_enc)\n",
    "            for layer in range(24):\n",
    "                logging.info(\n",
    "                    \"Computing RSA/RSA_regress scores for {} {} {}\".format(\n",
    "                        mode, step, layer\n",
    "                    )\n",
    "                )\n",
    "                data_enc = dict(\n",
    "                    test=data[\"bert24\"][\"test\"][mode][layer][step],\n",
    "                    ref=data[\"bert24\"][\"ref\"][mode][layer][step],\n",
    "                )\n",
    "                result[alpha][\"bert24\"][mode][step][layer] = RSA_report(\n",
    "                    data_tk, data_enc\n",
    "                )\n",
    "\n",
    "        result[alpha][\"infersent\"][mode] = RSA_report(\n",
    "            data_tk,\n",
    "            dict(\n",
    "                test=data[\"infersent\"][\"test\"][mode], ref=data[\"infersent\"][\"ref\"][mode]\n",
    "            ),\n",
    "        )\n",
    "    json.dump(result, open(\"report/RSA_natural.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code taken from: https://github.com/gchrupala/correlating-neural-and-symbolic-representations-of-language/blob/master/rsa/synsem.py\n",
    "\n",
    "\n",
    "def ewt_embed():\n",
    "    \"\"\"Compute BoW, BERT and Infersent embeddings for the EWT data and save to file.\"\"\"\n",
    "    import rsa.pretrained as Pre\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    def container():\n",
    "        return dict(\n",
    "            test=dict(random=dict(), trained=dict()),\n",
    "            ref=dict(random=dict(), trained=dict()),\n",
    "        )\n",
    "\n",
    "    data = json.load(open(\"data/out/ewt.json\"))\n",
    "    emb = dict(bow={}, bert=container(), bert24=container(), infersent=container())\n",
    "    # BOW\n",
    "    v = CountVectorizer(tokenizer=lambda x: x.split())\n",
    "    sent_ref = [s[\"sent\"] for s in data[\"ref\"]]\n",
    "    sent_test = [s[\"sent\"] for s in data[\"test\"]]\n",
    "    v.fit(sent_ref + sent_test)\n",
    "    emb[\"bow\"][\"test\"] = torch.tensor(\n",
    "        v.transform(sent_test).toarray(), dtype=torch.float\n",
    "    )\n",
    "    emb[\"bow\"][\"ref\"] = torch.tensor(v.transform(sent_ref).toarray(), dtype=torch.float)\n",
    "\n",
    "    for split in [\"test\", \"ref\"]:\n",
    "        sent = [datum[\"sent\"] for datum in data[split]]\n",
    "        for mode in [\"random\", \"trained\"]:\n",
    "            if mode == \"random\":\n",
    "                rep24 = list(Pre.encode_bert(sent, trained=False, large=True))\n",
    "                rep = list(Pre.encode_bert(sent, trained=False))\n",
    "                emb[\"infersent\"][split][mode] = Pre.encode_infersent(\n",
    "                    sent, trained=False\n",
    "                )\n",
    "            else:\n",
    "                rep24 = list(Pre.encode_bert(sent, trained=True, large=True))\n",
    "                rep = list(Pre.encode_bert(sent, trained=True))\n",
    "                emb[\"infersent\"][split][mode] = Pre.encode_infersent(sent, trained=True)\n",
    "\n",
    "            pooled24 = torch.cat([pooled for _, pooled in rep24])\n",
    "            pooled = torch.cat([pooled for _, pooled in rep])\n",
    "            emb[\"bert24\"][split][mode][\"pooled\"] = pooled24\n",
    "            emb[\"bert\"][split][mode][\"pooled\"] = pooled\n",
    "            for i in range(len(rep24[0][0])):\n",
    "                emb[\"bert24\"][split][mode][i] = {}\n",
    "                emb[\"bert24\"][split][mode][i][\"summed\"] = torch.cat(\n",
    "                    [layers[i].sum(dim=1) for layers, _ in rep24], dim=0\n",
    "                )\n",
    "                emb[\"bert24\"][split][mode][i][\"first\"] = torch.cat(\n",
    "                    [layers[i][:, 0, :] for layers, _ in rep24], dim=0\n",
    "                )\n",
    "                emb[\"bert24\"][split][mode][i][\"last\"] = torch.cat(\n",
    "                    [layers[i][:, -1, :] for layers, _ in rep24], dim=0\n",
    "                )\n",
    "\n",
    "            for i in range(len(rep[0][0])):\n",
    "                emb[\"bert\"][split][mode][i] = {}\n",
    "                emb[\"bert\"][split][mode][i][\"summed\"] = torch.cat(\n",
    "                    [layers[i].sum(dim=1) for layers, _ in rep], dim=0\n",
    "                )\n",
    "                emb[\"bert\"][split][mode][i][\"first\"] = torch.cat(\n",
    "                    [layers[i][:, 0, :] for layers, _ in rep], dim=0\n",
    "                )\n",
    "                emb[\"bert\"][split][mode][i][\"last\"] = torch.cat(\n",
    "                    [layers[i][:, -1, :] for layers, _ in rep], dim=0\n",
    "                )\n",
    "    torch.save(emb, \"data/out/ewt_embed.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
